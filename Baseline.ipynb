{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Knet\n",
    "using CSV\n",
    "using Random\n",
    "import Base: length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCHSIZE = 16\n",
    "VOCABFILE = \"bert-base-uncased-vocab.txt\"\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2int = Dict()\n",
    "f = open(VOCABFILE) do file\n",
    "    lines = readlines(file)\n",
    "    for (i,line) in enumerate(lines)\n",
    "        token2int[line] = i\n",
    "    end\n",
    "end\n",
    "int2token = Dict(value => key for (key, value) in token2int)\n",
    "VOCABSIZE = length(token2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"preprocess.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{String,1}:\n",
       " \"sense\" \n",
       " \"##less\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try any text here\n",
    "asd = convert_to_int_array(\"senseless\", token2int)\n",
    "[int2token[i] for i in asd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our minibatcher\n",
    "#=\n",
    "mutable struct SST\n",
    "    words\n",
    "    labels\n",
    "    batchsize\n",
    "    ninstances\n",
    "    shuffled\n",
    "end\n",
    "\n",
    "function SST(words, labels; batchsize=16, shuffled=false)\n",
    "    ninstances = length(words)\n",
    "    return SST(words, labels, batchsize, ninstances, shuffled)\n",
    "end\n",
    "\n",
    "function length(d::SST)\n",
    "    d, r = divrem(d.ninstances, d.batchsize)\n",
    "    return r == 0 ? d : d+1\n",
    "end\n",
    "\n",
    "function Base.iterate(d::SST, state=ifelse(d.shuffled, randperm(d.ninstances), 1:d.ninstances))\n",
    "    # START ANSWER\n",
    "    state === nothing && return nothing\n",
    "    if length(state) > d.batchsize\n",
    "        new_state = state[d.batchsize+1:end]\n",
    "        words = d.words[state[1:d.batchsize]]\n",
    "        labels = d.labels[state[1:d.batchsize]]\n",
    "    else\n",
    "        new_state = nothing\n",
    "        words = d.words[state]\n",
    "        labels = d.labels[state]\n",
    "    end\n",
    "    sorted_words = sort(map(x -> length(x), words))\n",
    "    max_len = length(words)\n",
    "    batchsizes = zeros(Int64, sorted_words[end]) # init with max seq length\n",
    "    for i in sorted_words\n",
    "        batchsizes[1:i] .+= 1\n",
    "    end\n",
    "    # END ANSWER\n",
    "    return ((words, labels, batchsizes), new_state)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Knet.Data{Tuple{Array{Array{Int64,1},1},Array{Int8,1}}}(Array{Int64,1}[[3626, 2006, 2024, 27817, 4039, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [2098, 2425, 2038, 8563, 29625, 19764, 6835, 6364, 2191, 2986  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1] … [6570, 3239, 1011, 10042, 2595, 1011, 15704, 1011, 3083, 29625  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1997, 11068, 1998, 1997, 2148, 8848, 6703, 1011, 5379, 2040  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], Int8[2 1 … 1 2], 16, 2000, false, 1985, 1:2000, false, (2000,), (2000,), Array{Array{Int64,1},1}, Array{Int8,1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dtrn = SST(read_and_process(\"mytrain.tsv\", token2int)...; batchsize=BATCHSIZE, shuffled=true)\n",
    "#ddev = SST(read_and_process(\"dev.tsv\", token2int)...; batchsize=BATCHSIZE)\n",
    "#dtst = SST(read_and_process(\"mytest.tsv\", token2int)...; batchsize=BATCHSIZE)\n",
    "dtrn = minibatch(read_and_process(\"mytrain.tsv\", token2int)..., BATCHSIZE; shuffle=true) # Mytrain is a subset of train set\n",
    "ddev = minibatch(read_and_process(\"dev.tsv\", token2int)..., BATCHSIZE)\n",
    "dtst = minibatch(read_and_process(\"mytest.tsv\", token2int)..., BATCHSIZE) # Mytest is a subset of train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"16-element Array{Array{Int64,1},1}\", \"16-element Array{Int8,1}\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.(first(dtrn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type Layer end\n",
    "\n",
    "struct Linear <: Layer\n",
    "    w\n",
    "    b\n",
    "    pdrop\n",
    "    func\n",
    "end\n",
    "\n",
    "function Linear(xsize::Int, ysize::Int; atype=KnetArray{Float32}, winit=xavier, binit=zeros, func=identity, pdrop=0.0)\n",
    "    Linear(Param(atype(winit(ysize,xsize))), Param(atype(binit(ysize))), pdrop, func)\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    l.func.(dropout(l.w * mat(x), l.pdrop)) .+ l.b\n",
    "end\n",
    "\n",
    "struct Embed <: Layer\n",
    "    w\n",
    "end\n",
    "\n",
    "Embed(vocabsize::Int,embed::Int) = Embed(param(embed,vocabsize))\n",
    "\n",
    "function (e::Embed)(x)\n",
    "    e.w[:,x]  # (B,T)->(X,B,T)->rnn->(H,B,T)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Chain <: Layer\n",
    "    layers\n",
    "end\n",
    "\n",
    "function Chain(all_layers::Array{Layer,1})\n",
    "    layers = Layer[]\n",
    "    for layer in all_layers\n",
    "        push!(layers, layer)\n",
    "    end\n",
    "    return Chain(tuple(layers...))\n",
    "end\n",
    "\n",
    "function (c::Chain)(x)\n",
    "    for layer in c.layers\n",
    "        x = layer(x)\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Baseline\n",
    "    pdrop\n",
    "    rnn::RNN\n",
    "    embed::Embed\n",
    "    layer::Layer\n",
    "end\n",
    "\n",
    "function Baseline(rnn_hidden::Int, embedsize::Int, vocabsize::Int, extra_layer::Layer; pdrop=0.0,  o...)\n",
    "    embed = Embed(vocabsize,embedsize)\n",
    "    rnn = RNN(embedsize,rnn_hidden;h=0,c=0,o...)\n",
    "    return Baseline(pdrop, rnn, embed, extra_layer)\n",
    "end\n",
    "\n",
    "#=\n",
    "function (b::Baseline)(x, batchsizes)\n",
    "    x = b.embed.(x)\n",
    "    x = b.rnn(x, batchSizes=batchsizes)\n",
    "    x = b.layer(dropout(x[:,:,end], b.pdrop))\n",
    "    return x\n",
    "end\n",
    "\n",
    "function (b::Baseline)(x, y::Array{Int8,1}, batchsizes)\n",
    "    nll(b(x, batchsizes), y)\n",
    "end\n",
    "\n",
    "function (b::Baseline)(d::SST)\n",
    "    lvals = []\n",
    "    for (x, y, batchsizes) in d\n",
    "        push!(lvals, b(x, y, batchsizes))\n",
    "    end\n",
    "    Knet.mean(lvals)\n",
    "end\n",
    "=#\n",
    "\n",
    "function (b::Baseline)(x)\n",
    "    x = permutedims(hcat(x...))\n",
    "    x = b.embed(x)\n",
    "    x = b.rnn(x)\n",
    "    x = b.layer(dropout(x[:,:,end], b.pdrop))\n",
    "    return x\n",
    "end\n",
    "\n",
    "function (b::Baseline)(x, y::Array{Int8,1})\n",
    "    nll(b(x), y)\n",
    "end\n",
    "\n",
    "function (b::Baseline)(d::Knet.Data)\n",
    "    lvals = []\n",
    "    for (x, y) in d\n",
    "        push!(lvals, b(x, y))\n",
    "    end\n",
    "    Knet.mean(lvals)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy2 (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function accuracy2(model, d)\n",
    "    true_count = 0\n",
    "    all_count = 0\n",
    "    for (x, y) in d\n",
    "        true_count += sum(y' .== map(x -> x[1], argmax(Array{Float32}(model(x)),dims=1)))\n",
    "        all_count += length(y)\n",
    "    end\n",
    "    return true_count/all_count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "6.86e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:34/00:34, 120.59i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Saving...\n",
      "Epoch : 2\n",
      "6.97e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.70i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 3\n",
      "7.10e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.42i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 4\n",
      "6.58e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.18i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 5\n",
      "6.75e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.80i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 6\n",
      "6.85e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.10i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 7\n",
      "7.14e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.84i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 8\n",
      "6.60e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.67i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 9\n",
      "6.99e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.24i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 10\n",
      "7.15e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.49i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 11\n",
      "6.70e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.86i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 12\n",
      "7.09e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.34i/s]\n",
      "Accuracy : 0.5081018518518519\n",
      "Epoch : 13\n",
      "7.45e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.41i/s]\n",
      "Accuracy : 0.5081018518518519\n",
      "Epoch : 14\n",
      "6.73e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.00i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 15\n",
      "6.68e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.18i/s]\n",
      "Accuracy : 0.5081018518518519\n",
      "Epoch : 16\n",
      "6.71e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.65i/s]\n",
      "Accuracy : 0.5092592592592593\n",
      "Epoch : 17\n",
      "7.18e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.23i/s]\n",
      "Accuracy : 0.5081018518518519\n",
      "Epoch : 18\n",
      "6.66e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.27i/s]\n",
      "Accuracy : 0.5081018518518519\n",
      "Epoch : 19\n",
      "6.86e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.55i/s]\n",
      "Accuracy : 0.5081018518518519\n",
      "Epoch : 20\n",
      "6.51e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.16i/s]\n",
      "Accuracy : 0.5081018518518519\n",
      "Epoch : 21\n",
      "4.10e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.78i/s]\n",
      "Accuracy : 0.7430555555555556\n",
      "Saving...\n",
      "Epoch : 22\n",
      "1.18e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.73i/s]\n",
      "Accuracy : 0.8020833333333334\n",
      "Saving...\n",
      "Epoch : 23\n",
      "3.53e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.97i/s]\n",
      "Accuracy : 0.8217592592592593\n",
      "Saving...\n",
      "Epoch : 24\n",
      "3.34e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.60i/s]\n",
      "Accuracy : 0.8171296296296297\n",
      "Epoch : 25\n",
      "6.94e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.15i/s]\n",
      "Accuracy : 0.8125\n",
      "Epoch : 26\n",
      "1.02e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.62i/s]\n",
      "Accuracy : 0.8067129629629629\n",
      "Epoch : 27\n",
      "1.27e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.60i/s]\n",
      "Accuracy : 0.7951388888888888\n",
      "Epoch : 28\n",
      "6.95e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.38i/s]\n",
      "Accuracy : 0.8032407407407407\n",
      "Epoch : 29\n",
      "1.71e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.59i/s]\n",
      "Accuracy : 0.7916666666666666\n",
      "Epoch : 30\n",
      "2.49e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.69i/s]\n",
      "Accuracy : 0.7939814814814815\n",
      "Epoch : 31\n",
      "7.62e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.33i/s]\n",
      "Accuracy : 0.7835648148148148\n",
      "Epoch : 32\n",
      "4.77e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.39i/s]\n",
      "Accuracy : 0.7939814814814815\n",
      "Epoch : 33\n",
      "3.49e-01  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.03i/s]\n",
      "Accuracy : 0.7962962962962963\n",
      "Epoch : 34\n",
      "1.62e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.14i/s]\n",
      "Accuracy : 0.7939814814814815\n",
      "Epoch : 35\n",
      "2.39e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.48i/s]\n",
      "Accuracy : 0.7719907407407407\n",
      "Epoch : 36\n",
      "1.14e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.87i/s]\n",
      "Accuracy : 0.8136574074074074\n",
      "Epoch : 37\n",
      "1.12e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.88i/s]\n",
      "Accuracy : 0.7858796296296297\n",
      "Epoch : 38\n",
      "5.32e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.45i/s]\n",
      "Accuracy : 0.7789351851851852\n",
      "Epoch : 39\n",
      "7.20e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.16i/s]\n",
      "Accuracy : 0.7881944444444444\n",
      "Epoch : 40\n",
      "2.26e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.65i/s]\n",
      "Accuracy : 0.7928240740740741\n",
      "Epoch : 41\n",
      "1.77e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.55i/s]\n",
      "Accuracy : 0.7789351851851852\n",
      "Epoch : 42\n",
      "5.73e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.05i/s]\n",
      "Accuracy : 0.7974537037037037\n",
      "Epoch : 43\n",
      "2.66e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.39i/s]\n",
      "Accuracy : 0.7731481481481481\n",
      "Epoch : 44\n",
      "2.77e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.74i/s]\n",
      "Accuracy : 0.7800925925925926\n",
      "Epoch : 45\n",
      "3.32e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.97i/s]\n",
      "Accuracy : 0.7870370370370371\n",
      "Epoch : 46\n",
      "4.94e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.38i/s]\n",
      "Accuracy : 0.8043981481481481\n",
      "Epoch : 47\n",
      "1.82e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.65i/s]\n",
      "Accuracy : 0.7939814814814815\n",
      "Epoch : 48\n",
      "2.56e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.72i/s]\n",
      "Accuracy : 0.7800925925925926\n",
      "Epoch : 49\n",
      "1.02e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.52i/s]\n",
      "Accuracy : 0.7870370370370371\n",
      "Epoch : 50\n",
      "6.32e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.80i/s]\n",
      "Accuracy : 0.7581018518518519\n",
      "Epoch : 51\n",
      "8.35e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.53i/s]\n",
      "Accuracy : 0.7916666666666666\n",
      "Epoch : 52\n",
      "5.40e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.56i/s]\n",
      "Accuracy : 0.7905092592592593\n",
      "Epoch : 53\n",
      "2.47e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.02i/s]\n",
      "Accuracy : 0.7835648148148148\n",
      "Epoch : 54\n",
      "1.00e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.35i/s]\n",
      "Accuracy : 0.78125\n",
      "Epoch : 55\n",
      "8.95e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.12i/s]\n",
      "Accuracy : 0.7916666666666666\n",
      "Epoch : 56\n",
      "6.13e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.86i/s]\n",
      "Accuracy : 0.7881944444444444\n",
      "Epoch : 57\n",
      "9.07e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.39i/s]\n",
      "Accuracy : 0.7754629629629629\n",
      "Epoch : 58\n",
      "5.94e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.98i/s]\n",
      "Accuracy : 0.7800925925925926\n",
      "Epoch : 59\n",
      "6.30e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.60i/s]\n",
      "Accuracy : 0.7777777777777778\n",
      "Epoch : 60\n",
      "7.68e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.62i/s]\n",
      "Accuracy : 0.7743055555555556\n",
      "Epoch : 61\n",
      "9.17e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.13i/s]\n",
      "Accuracy : 0.7824074074074074\n",
      "Epoch : 62\n",
      "4.97e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.48i/s]\n",
      "Accuracy : 0.75\n",
      "Epoch : 63\n",
      "1.31e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.94i/s]\n",
      "Accuracy : 0.7685185185185185\n",
      "Epoch : 64\n",
      "8.18e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.71i/s]\n",
      "Accuracy : 0.7916666666666666\n",
      "Epoch : 65\n",
      "9.54e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.31i/s]\n",
      "Accuracy : 0.78125\n",
      "Epoch : 66\n",
      "3.93e-06  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.00i/s]\n",
      "Accuracy : 0.7847222222222222\n",
      "Epoch : 67\n",
      "1.55e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.83i/s]\n",
      "Accuracy : 0.7835648148148148\n",
      "Epoch : 68\n",
      "1.98e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.48i/s]\n",
      "Accuracy : 0.7824074074074074\n",
      "Epoch : 69\n",
      "1.87e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.25i/s]\n",
      "Accuracy : 0.7858796296296297\n",
      "Epoch : 70\n",
      "5.43e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.75i/s]\n",
      "Accuracy : 0.7870370370370371\n",
      "Epoch : 71\n",
      "5.01e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.41i/s]\n",
      "Accuracy : 0.7858796296296297\n",
      "Epoch : 72\n",
      "2.47e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.19i/s]\n",
      "Accuracy : 0.7835648148148148\n",
      "Epoch : 73\n",
      "6.57e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.40i/s]\n",
      "Accuracy : 0.7708333333333334\n",
      "Epoch : 74\n",
      "1.13e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.74i/s]\n",
      "Accuracy : 0.7974537037037037\n",
      "Epoch : 75\n",
      "6.70e-02  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.83i/s]\n",
      "Accuracy : 0.7962962962962963\n",
      "Epoch : 76\n",
      "2.73e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.47i/s]\n",
      "Accuracy : 0.7824074074074074\n",
      "Epoch : 77\n",
      "9.60e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.62i/s]\n",
      "Accuracy : 0.7824074074074074\n",
      "Epoch : 78\n",
      "7.02e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.67i/s]\n",
      "Accuracy : 0.7974537037037037\n",
      "Epoch : 79\n",
      "6.38e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.44i/s]\n",
      "Accuracy : 0.7893518518518519\n",
      "Epoch : 80\n",
      "1.64e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.98i/s]\n",
      "Accuracy : 0.7916666666666666\n",
      "Epoch : 81\n",
      "6.77e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.52i/s]\n",
      "Accuracy : 0.7824074074074074\n",
      "Epoch : 82\n",
      "3.39e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.60i/s]\n",
      "Accuracy : 0.7974537037037037\n",
      "Epoch : 83\n",
      "2.67e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.90i/s]\n",
      "Accuracy : 0.7916666666666666\n",
      "Epoch : 84\n",
      "5.22e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.30i/s]\n",
      "Accuracy : 0.7743055555555556\n",
      "Epoch : 85\n",
      "2.00e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.03i/s]\n",
      "Accuracy : 0.7650462962962963\n",
      "Epoch : 86\n",
      "4.71e-06  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.32i/s]\n",
      "Accuracy : 0.7662037037037037\n",
      "Epoch : 87\n",
      "3.53e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 152.08i/s]\n",
      "Accuracy : 0.7673611111111112\n",
      "Epoch : 88\n",
      "2.03e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.39i/s]\n",
      "Accuracy : 0.7696759259259259\n",
      "Epoch : 89\n",
      "2.25e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.77i/s]\n",
      "Accuracy : 0.7662037037037037\n",
      "Epoch : 90\n",
      "1.78e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.51i/s]\n",
      "Accuracy : 0.7858796296296297\n",
      "Epoch : 91\n",
      "2.15e-06  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.81i/s]\n",
      "Accuracy : 0.7766203703703703\n",
      "Epoch : 92\n",
      "5.40e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.62i/s]\n",
      "Accuracy : 0.7708333333333334\n",
      "Epoch : 93\n",
      "6.91e-05  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.84i/s]\n",
      "Accuracy : 0.7638888888888888\n",
      "Epoch : 94\n",
      "4.51e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.61i/s]\n",
      "Accuracy : 0.7766203703703703\n",
      "Epoch : 95\n",
      "3.52e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.83i/s]\n",
      "Accuracy : 0.7604166666666666\n",
      "Epoch : 96\n",
      "5.15e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.61i/s]\n",
      "Accuracy : 0.78125\n",
      "Epoch : 97\n",
      "8.64e-06  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 150.95i/s]\n",
      "Accuracy : 0.7719907407407407\n",
      "Epoch : 98\n",
      "1.14e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.83i/s]\n",
      "Accuracy : 0.7835648148148148\n",
      "Epoch : 99\n",
      "1.52e-03  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.47i/s]\n",
      "Accuracy : 0.7754629629629629\n",
      "Epoch : 100\n",
      "7.82e-04  100.00%┣██████████████████████████▉┫ 4084/4084 [00:27/00:27, 151.14i/s]\n",
      "Accuracy : 0.7870370370370371\n"
     ]
    }
   ],
   "source": [
    "model = Baseline(256, 128, VOCABSIZE, Chain([Linear(256,512, func=relu), Linear(512,NUM_CLASSES)]))\n",
    "trnloss = [model(dtrn)]\n",
    "devloss = [model(ddev)]\n",
    "best_acc = 0.0\n",
    "for epoch in 1:100\n",
    "    println(\"Epoch : \", epoch)\n",
    "    progress!(adam(model, dtrn))\n",
    "    push!(trnloss, model(dtrn))\n",
    "    push!(devloss, model(ddev))\n",
    "    acc = accuracy(model, ddev)\n",
    "    println(\"Accuracy : \", acc)\n",
    "    if acc > best_acc\n",
    "        best_acc = acc\n",
    "        println(\"Saving...\")\n",
    "        Knet.save(\"model.jld2\", \"model\", model)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2(model, dtst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
